{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40b8b45a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dehuang/.pyenv/versions/3.9.6/lib/python3.9/site-packages/pandas/compat/__init__.py:124: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from os.path import exists\n",
    "import requests\n",
    "from typing import *\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import trange, tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3591ce",
   "metadata": {},
   "source": [
    "# Homework 3: Optimization and Regression, Due October 14, 2022\n",
    "\n",
    "1. Answer each question.\n",
    "2. Feel free to leave in testing code and other visualization code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916d1cfa",
   "metadata": {},
   "source": [
    "## Problem 1 (30 pts): A Fully Connected and Single-Layer Neural Network\n",
    "\n",
    "Suppose we are fitting a regression model to a dataset $(x_i, y_i)_{1 \\leq i \\leq N}$\n",
    "\\begin{align*}\n",
    "p(y^i|x^i; A, \\mu) & = \\mathcal{N}(f(Ax^i + \\mu), 1) \\\\\n",
    "p(y |x; A, \\mu) & = \\prod_{i=1}^N p(y^i|x^i; A, \\mu)\n",
    "\\end{align*}\n",
    "where\n",
    "1. the inputs $x^i \\in \\mathbb{R}^d$ are d-D vectors\n",
    "2. $A$ is a $1 \\times d$ matrix of weights\n",
    "$$\n",
    "A = \\begin{pmatrix}\n",
    "a_{11} & \\dots & a_{1d} \n",
    "\\end{pmatrix}\n",
    "$$\n",
    "3. $f: \\mathbb{R} \\rightarrow \\mathbb{R}$ is some function\n",
    "4. $x$ is a $Nxd$ matrix where row $i$ contains $x^i$\n",
    "$$\n",
    "x = \\begin{pmatrix}\n",
    "- & x^1 & -\\\\\n",
    "\\vdots & \\vdots & \\vdots\\\\\n",
    "- & x^N & -\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "5. $y$ is a vector of values to regress against\n",
    "$$\n",
    "y = \\begin{pmatrix}\n",
    "y^1 \\\\\n",
    "\\vdots \\\\\n",
    "y^N\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "6. $\\mu \\in \\mathbb{R}$ is an offset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48dd24a",
   "metadata": {},
   "source": [
    "### Problem 1a (10 pts)\n",
    "\n",
    "Implement the conditional density:\n",
    "$$\n",
    "p(y |x; A, \\mu) = \\prod_{i=1}^N p(y^i|x^i; A, \\mu)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e74537c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model1_density(f: Callable[[float], float],\n",
    "                   A: np.ndarray,\n",
    "                   mu: float) -> Callable[[np.ndarray, np.ndarray], float]:\n",
    "    # Inputs:\n",
    "    #     f is some function\n",
    "    #     A is a 1xd matrix\n",
    "    #     mu is a float indicating the constant offset\n",
    "    #\n",
    "    # Outputs:\n",
    "    #     Return the density as a function of the dataset x and y\n",
    "    def density(x: np.ndarray, y: np.ndarray) -> float:\n",
    "        # Inputs:\n",
    "        #     x is a Nxd matrix where each row is a datapoint\n",
    "        #\n",
    "        # Outputs:\n",
    "        #     y is a length n vector to evaluate the density on\n",
    "        pass\n",
    "    \n",
    "    return density"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9ee197",
   "metadata": {},
   "source": [
    "### Problem 1b (10 pts)\n",
    "\n",
    "Derive and implement\n",
    "$$\n",
    "\\frac{\\partial}{\\partial A} p(y |x; A, \\mu)\n",
    "$$\n",
    "and\n",
    "$$\n",
    "\\frac{\\partial}{\\partial \\mu} p(y |x; A, \\mu) \\,.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28d56465",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_A(f: Callable[[float], float],\n",
    "           grad_f: Callable[[float], float],\n",
    "           A: np.ndarray,\n",
    "           mu: float,\n",
    "           x: np.ndarray,\n",
    "           y: np.ndarray) -> np.ndarray:\n",
    "    # Inputs:\n",
    "    #     f is some function\n",
    "    #     grad_f is the gradient of f\n",
    "    #     A is a 1xd matrix\n",
    "    #     mu is a float indicating the constant offset\n",
    "    #.    x is a nxd matrix of inputs\n",
    "    #     y is a length n vector of regression outputs\n",
    "    #\n",
    "    # Outputs:\n",
    "    #     Return the gradient of the conditional density w.r.t. the matrix A, which should be a 1xd matrix.\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ab93281",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_mu(f: Callable[[float], float],\n",
    "            grad_f: Callable[[float], float],\n",
    "            A: np.ndarray,\n",
    "            mu: float,\n",
    "            x: np.ndarray,\n",
    "            y: np.ndarray) -> float:\n",
    "    # Inputs:\n",
    "    #     f is some function\n",
    "    #     grad_f is the gradient of f\n",
    "    #     A is a 1xd matrix\n",
    "    #     mu is a float indicating the constant offset\n",
    "    #.    x is a nxd matrix of inputs\n",
    "    #     y is a length n vector of regression outputs\n",
    "    #\n",
    "    # Outputs:\n",
    "    #     Return the gradient of the conditional density w.r.t. the offset mu, which should be a float.\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9386f892",
   "metadata": {},
   "source": [
    "### Problem 1c (10 pts)\n",
    "\n",
    "Write a function that solves for the weights by finding the approximate minimum of the conditional density, i.e., solve\n",
    "$$\n",
    "\\operatorname{argmin}_{A, \\mu} -p(y | x; A, \\mu)\n",
    "$$\n",
    "with **stochastic gradient descent**. Hint: you may want to use the negative log-likelihood trick."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d5c3e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_for_weights(f: Callable[[float], float],\n",
    "                      grad_f: Callable[[float], float],\n",
    "                      A: np.ndarray,\n",
    "                      mu: float,\n",
    "                      initial_A: np.ndarray,\n",
    "                      initial_mu: np.ndarray,\n",
    "                      step_size: float,\n",
    "                      batch_size: int) -> Tuple[np.ndarray, float]:\n",
    "    # Inputs:\n",
    "    #     f is some function\n",
    "    #     grad_f is the gradient of f\n",
    "    #     A is a 1xd matrix\n",
    "    #     mu is a float indicating the constant offset\n",
    "    #     initial_A is a 1xd matrix containing the initial guess of A for stochastic gradient descent\n",
    "    #     initial_mu is a float containing the initial guess of mu for stochastic gradient descent\n",
    "    #     step_size is a the step size of stochastic gradient descent\n",
    "    #     batch_size is the batch size of stochastic gradient descent    \n",
    "    #\n",
    "    # Outputs:\n",
    "    #     Return the density as a function of the dataset x and y\n",
    "    best_A = np.zeros(A.shape)\n",
    "    best_mu = 0.\n",
    "    \n",
    "    # TODO: fill me in\n",
    "    \n",
    "    return best_A, best_mu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c402d3b5",
   "metadata": {},
   "source": [
    "## Problem 2 (50 pts): A Fully Connected and Two-Layer Neural Network\n",
    "\n",
    "Suppose we are fitting a regression model to a dataset $(x_i, y_i)_{1 \\leq i \\leq N}$\n",
    "\\begin{align*}\n",
    "p(y^i|x^i; A_1, \\mu_1, A_2, \\mu_2) & = \\mathcal{N}(f(A_2 f(A_1x^i + \\mu_1) + \\mu_2), 1) \\\\\n",
    "p(y |x; A_1, \\mu_1, A_2, \\mu_2) & = \\prod_{i=1}^N p(y^i|x^i; A_1, \\mu_1, A_2, \\mu_2)\n",
    "\\end{align*}\n",
    "where\n",
    "1. the inputs $x^i \\in \\mathbb{R}^d$ are d-D vectors\n",
    "2. $A_1$ is a $m \\times d$ matrix of weights and $A_2$ is a $1 \\times m$ matrix of weights.\n",
    "$$\n",
    "A = \\begin{pmatrix}\n",
    "a_{11} & \\dots & a_{1d} \n",
    "\\end{pmatrix}\n",
    "$$\n",
    "3. $\\mu_1 \\in \\mathbb{R}^m$ is a vector of weights and $\\mu_2 \\in \\mathbb{R}$ is a weight.\n",
    "4. $f: \\mathbb{R} \\rightarrow \\mathbb{R}$ is some function\n",
    "5. $x$ is a $Nxd$ matrix where row $i$ contains $x^i$\n",
    "$$\n",
    "x = \\begin{pmatrix}\n",
    "- & x^1 & -\\\\\n",
    "\\vdots & \\vdots & \\vdots\\\\\n",
    "- & x^N & -\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "6. $y$ is a vector of values to regress against\n",
    "$$\n",
    "y = \\begin{pmatrix}\n",
    "y^1 \\\\\n",
    "\\vdots \\\\\n",
    "y^N\n",
    "\\end{pmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe9f7c5",
   "metadata": {},
   "source": [
    "### Problem 2a (10 pts)\n",
    "\n",
    "Implement the conditional density:\n",
    "$$\n",
    "p(y |x; A_1, \\mu_1, A_2, \\mu_2) = \\prod_{i=1}^N p(y^i|x^i; A_1, \\mu_1, A_2, \\mu_2)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1fbf9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model2_density(f: Callable[[float], float],\n",
    "                   A1: np.ndarray,\n",
    "                   mu1: float,\n",
    "                   A2: np.ndarray,\n",
    "                   mu2: float) -> Callable[[np.ndarray, np.ndarray], float]:\n",
    "    # Inputs:\n",
    "    #     f is some function\n",
    "    #     A1 is a mxd matrix\n",
    "    #     mu1 is a length m vector\n",
    "    #     A2 is a 1xm matrix\n",
    "    #     mu2 is a float indicating the constant offset\n",
    "    #\n",
    "    # Outputs:\n",
    "    #     Return the density as a function of the dataset x and y\n",
    "    def density(x: np.ndarray, y: np.ndarray) -> float:\n",
    "        # Inputs:\n",
    "        #     x is a Nxd matrix where each row is a datapoint\n",
    "        #\n",
    "        # Outputs:\n",
    "        #     y is a length n vector to evaluate the density on\n",
    "        pass\n",
    "    \n",
    "    return density"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34641d3",
   "metadata": {},
   "source": [
    "### Problem 2b (15 pts)\n",
    "\n",
    "Derive and implement\n",
    "$$\n",
    "\\frac{\\partial}{\\partial A_1} p(y |x; A_1, \\mu_1, A_2, \\mu_2)\n",
    "$$\n",
    "and\n",
    "$$\n",
    "\\frac{\\partial}{\\partial \\mu_1} p(y |x; A_1, \\mu_1, A_2, \\mu_2) \\,.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24626e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_A1(f: Callable[[float], float],\n",
    "            grad_f: Callable[[float], float],\n",
    "            A1: np.ndarray,\n",
    "            mu1: float,\n",
    "            A2: np.ndarray,\n",
    "            mu2: float,\n",
    "            x: np.ndarray,\n",
    "            y: np.ndarray) -> np.ndarray:\n",
    "    # Inputs:\n",
    "    #     f is some function\n",
    "    #     grad_f is the gradient of f\n",
    "    #     A1 is a mxd matrix of weights\n",
    "    #     mu1 is a vector of constant offsets\n",
    "    #     A2 is a 1xm matrix of weights\n",
    "    #     mu2 is a float that is a constant offset\n",
    "    #     x is a nxd matrix of inputs\n",
    "    #     y is a length n vector of regression outputs\n",
    "    #\n",
    "    # Outputs:\n",
    "    #     Return the gradient of the conditional density w.r.t. the matrix A, which should be a 1xd matrix.\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38d1b8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_mu1(f: Callable[[float], float],\n",
    "            grad_f: Callable[[float], float],\n",
    "            A1: np.ndarray,\n",
    "            mu1: float,\n",
    "            A2: np.ndarray,\n",
    "            mu2: float,\n",
    "            x: np.ndarray,\n",
    "            y: np.ndarray) -> np.ndarray:\n",
    "    # Inputs:\n",
    "    #     f is some function\n",
    "    #     grad_f is the gradient of f\n",
    "    #     A1 is a mxd matrix of weights\n",
    "    #     mu1 is a vector of constant offsets\n",
    "    #     A2 is a 1xm matrix of weights\n",
    "    #     mu2 is a float that is a constant offset\n",
    "    #     x is a nxd matrix of inputs\n",
    "    #     y is a length n vector of regression outputs\n",
    "    #\n",
    "    # Outputs:\n",
    "    #     Return the gradient of the conditional density w.r.t. the matrix A, which should be a 1xd matrix.\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1e0552",
   "metadata": {},
   "source": [
    "### Problem 2c (15 pts)\n",
    "\n",
    "Derive and implement\n",
    "$$\n",
    "\\frac{\\partial}{\\partial A_2} p(y |x; A_1, \\mu_1, A_2, \\mu_2)\n",
    "$$\n",
    "and\n",
    "$$\n",
    "\\frac{\\partial}{\\partial \\mu_2} p(y |x; A_1, \\mu_1, A_2, \\mu_2) \\,.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "122c1f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_A2(f: Callable[[float], float],\n",
    "            grad_f: Callable[[float], float],\n",
    "            A1: np.ndarray,\n",
    "            mu1: float,\n",
    "            A2: np.ndarray,\n",
    "            mu2: float,\n",
    "            x: np.ndarray,\n",
    "            y: np.ndarray) -> np.ndarray:\n",
    "    # Inputs:\n",
    "    #     f is some function\n",
    "    #     grad_f is the gradient of f\n",
    "    #     A1 is a mxd matrix of weights\n",
    "    #     mu1 is a vector of constant offsets\n",
    "    #     A2 is a 1xm matrix of weights\n",
    "    #     mu2 is a float that is a constant offset\n",
    "    #     x is a nxd matrix of inputs\n",
    "    #     y is a length n vector of regression outputs\n",
    "    #\n",
    "    # Outputs:\n",
    "    #     Return the gradient of the conditional density w.r.t. the matrix A, which should be a 1xd matrix.\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f071e612",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_mu2(f: Callable[[float], float],\n",
    "             grad_f: Callable[[float], float],\n",
    "             A1: np.ndarray,\n",
    "             mu1: float,\n",
    "             A2: np.ndarray,\n",
    "             mu2: float,\n",
    "             x: np.ndarray,\n",
    "             y: np.ndarray) -> float:\n",
    "    # Inputs:\n",
    "    #     f is some function\n",
    "    #     grad_f is the gradient of f\n",
    "    #     A1 is a mxd matrix of weights\n",
    "    #     mu1 is a vector of constant offsets\n",
    "    #     A2 is a 1xm matrix of weights\n",
    "    #     mu2 is a float that is a constant offset\n",
    "    #     x is a nxd matrix of inputs\n",
    "    #     y is a length n vector of regression outputs\n",
    "    #\n",
    "    # Outputs:\n",
    "    #     Return the gradient of the conditional density w.r.t. the matrix A, which should be a 1xd matrix.\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8068a990",
   "metadata": {},
   "source": [
    "### Problem 2d (10 pts)\n",
    "\n",
    "Write a function that solves for the weights by finding the approximate minimum of the conditional density, i.e., solve\n",
    "$$\n",
    "\\operatorname{argmin}_{A_1, \\mu_1, A_2, \\mu_2} -p(y | x; A_1, \\mu_1, A_2, \\mu_2)\n",
    "$$\n",
    "with **stochastic gradient descent**. Hint: you may want to use the negative log-likelihood trick."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05064f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_for_weights(f: Callable[[float], float],\n",
    "                      grad_f: Callable[[float], float],\n",
    "                      A1: np.ndarray,\n",
    "                      mu1: np.ndarray,\n",
    "                      A2: np.ndarray,\n",
    "                      mu2: float,\n",
    "                      initial_A1: np.ndarray,\n",
    "                      initial_mu1: np.ndarray,\n",
    "                      initial_A2: np.ndarray,\n",
    "                      initial_mu2: float,\n",
    "                      step_size: float,\n",
    "                      batch_size: int) -> Tuple[np.ndarray, float]:\n",
    "    # Inputs:\n",
    "    #     f is some function\n",
    "    #     grad_f is the gradient of f\n",
    "    #     A1 is a mxd matrix of weights\n",
    "    #     mu1 is a vector of constant offsets\n",
    "    #     A2 is a 1xm matrix of weights\n",
    "    #     mu2 is a float that is a constant offset\n",
    "    #     initial_A1 is a mxd matrix containing the initial guess of A1 for stochastic gradient descent\n",
    "    #     initial_mu1 is a length d vector containing the initial guess of mu1 for stochastic gradient descent\n",
    "    #     initial_A2 is a 1xm matrix containing the initial guess of A2 for stochastic gradient descent\n",
    "    #     initial_mu2 is a float containing the initial guess of mu2 for stochastic gradient descent\n",
    "    #     step_size is a the step size of stochastic gradient descent\n",
    "    #     batch_size is the batch size of stochastic gradient descent    \n",
    "    #\n",
    "    # Outputs:\n",
    "    #     Return the density as a function of the dataset x and y\n",
    "    best_A = np.zeros(A.shape)\n",
    "    best_mu = 0.\n",
    "    \n",
    "    # TODO: fill me in\n",
    "    \n",
    "    return best_A, best_mu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f134a92",
   "metadata": {},
   "source": [
    "### Problem 3 (20 pts): Multi-output Regression\n",
    "\n",
    "Suppose we are fitting a regression model to a dataset $(x_i, y_i)_{1 \\leq i \\leq N}$\n",
    "\\begin{align*}\n",
    "p(y^i|x^i; A, \\mu, \\Sigma) & = \\mathcal{N}(f(Ax^i + \\mu), \\Sigma) \\\\\n",
    "p(y |x; A, \\mu, \\Sigma) & = \\prod_{i=1}^N p(y^i|x^i; A, \\mu, \\Sigma)\n",
    "\\end{align*}\n",
    "where\n",
    "1. the inputs $x^i \\in \\mathbb{R}^d$ are d-D vectors\n",
    "2. $A$ is a $2 \\times d$ matrix of weights\n",
    "$$\n",
    "A = \\begin{pmatrix}\n",
    "a_{11} & \\dots & a_{1d} \\\\\n",
    "a_{21} & \\dots & a_{2d}\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "3. $f: \\mathbb{R} \\rightarrow \\mathbb{R}$ is some function\n",
    "4. $x$ is a $Nxd$ matrix where row $i$ contains $x^i$\n",
    "$$\n",
    "x = \\begin{pmatrix}\n",
    "- & x^1 & -\\\\\n",
    "\\vdots & \\vdots & \\vdots\\\\\n",
    "- & x^N & -\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "5. $y$ is a $Nx2$ matrix of values to regress against\n",
    "$$\n",
    "y = \\begin{pmatrix}\n",
    "y^1_1 & y^1_2\\\\\n",
    "\\vdots \\\\\n",
    "y^N_1 & y^N_2\\\\\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "6. $\\Sigma$ is a covariance matrix\n",
    "$$\n",
    "\\begin{pmatrix}\n",
    "\\sigma_{11} & \\sigma_{12} \\\\\n",
    "\\sigma_{21} & \\sigma_{22}\n",
    "\\end{pmatrix}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48db5d7d",
   "metadata": {},
   "source": [
    "### Problem 3a (10 pts)\n",
    "\n",
    "Suppose we are solving for\n",
    "$$\n",
    "\\operatorname{argmin}_{A, \\mu} -p(y | x; A, \\mu, \\Sigma) \\,.\n",
    "$$\n",
    "\n",
    "Derive the associated loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b290d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILL ME IN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5712479",
   "metadata": {},
   "source": [
    "### Problem 3b (10 pts)\n",
    "\n",
    "Compare and contrast the situation when $\\Sigma$ is an identity matrix and when it is not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "598052fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILL ME IN"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
